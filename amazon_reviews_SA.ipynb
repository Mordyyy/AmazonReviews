{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import gcld3\n",
    "from pycountry import languages\n",
    "import transformers\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "import translators as ts\n",
    "from autocorrect import Speller\n",
    "import re\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns text's language\n",
    "# speed or FastText would be better\n",
    "\n",
    "def detect_language(text):\n",
    "    detector = gcld3.NNetLanguageIdentifier(min_num_bytes=0, \n",
    "                                        max_num_bytes=100000)\n",
    "    result = detector.FindLanguage(text=text)\n",
    "    if languages.get(alpha_2=result.language) == None:\n",
    "        return None\n",
    "    return languages.get(alpha_2=result.language).name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "## translates to English\n",
    "\n",
    "def translate(text):\n",
    "    return ts.google(text, if_use_cn_host=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "## removes urls\n",
    "\n",
    "def remove_url(text):\n",
    "    text = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0–9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0–9@:%_\\+.~#?&//=]*)', '', \n",
    "                   text, flags=re.MULTILINE)  # to remove links that start with HTTP/HTTPS in the tweet\n",
    "    text = re.sub(r'[-a-zA-Z0–9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0–9@:%_\\+.~#?&//=]*)', '', \n",
    "                   text, flags=re.MULTILINE) # to remove other url links\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "## removes emoji\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags \n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "## removes numbers and punctuations\n",
    "\n",
    "def remove_nums_punctuations(text): \n",
    "    punctuations = '''!()-![]{};:+'\"\\,<>./?@#$%^&*_~'''\n",
    "    nums = '0123456789'\n",
    "    return ''.join([i for i in text if i not in punctuations and i not in nums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting apostrophe/short words in the better form\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "## removes extra white spaces\n",
    "\n",
    "def remove_extra_whitespaces(text):\n",
    "    return re.sub(' {2,}', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "## removes specific stop words\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    stop_words=['in','of','at','a','the, i, them, you, their, myself, our, ours, me, he, him, it, ours']\n",
    "    tokens = text.split(' ')\n",
    "    return ' '.join([word for word in tokens if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "## spell checker\n",
    "\n",
    "def spell_check(text):\n",
    "    spell = Speller('en')\n",
    "    s = ' '.join([spell(w) for w in text.split(' ')])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = remove_extra_whitespaces(text)\n",
    "    text = remove_url(text)\n",
    "    text = remove_emoji(text)\n",
    "    text = remove_nums_punctuations(text)\n",
    "    text = spell_check(text)\n",
    "    text = decontracted(text)\n",
    "    text = remove_stop_words(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '/Users/test/Downloads/archive/train.ft.txt'\n",
    "TEST_PATH = '/Users/test/Downloads/archive/test.ft.txt'\n",
    "NEW_TRAIN_PATH = '/Users/test/Downloads/archive/new_train.ft.txt'\n",
    "NEW_TEST_PATH = '/Users/test/Downloads/archive/new_test.ft.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt = open(TRAIN_PATH, \"r\")\n",
    "new_train_txt = open(NEW_TRAIN_PATH, \"w\")\n",
    "p = 0.0\n",
    "cnt = 0.0\n",
    "for line in train_txt:\n",
    "    if detect_language(line[10:]) == 'English':\n",
    "        preprocessed = line[:10] + preprocess(line[10:])\n",
    "        new_train_txt.write(preprocessed)\n",
    "    if cnt == 36000:\n",
    "        break\n",
    "    if cnt == 360*p:\n",
    "        print(str(p) + '%')\n",
    "        p+=1\n",
    "    cnt+=1\n",
    "train_txt.close()\n",
    "new_train_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_txt = open(TEST_PATH, \"r\")\n",
    "new_test_txt = open(NEW_TEST_PATH, \"w\")\n",
    "for line in test_txt:\n",
    "    review = line[10:]\n",
    "    language = detect_language(review)\n",
    "    if language == None:\n",
    "        continue\n",
    "    if language != 'English':\n",
    "        review = translate(review)\n",
    "    preprocessed = line[:10] + preprocessed(review)\n",
    "    new_test_txt.write(preprocessed)\n",
    "test_txt.close()\n",
    "new_test_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(NEW_TRAIN_PATH, wordNgrams=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_size=400000\n",
      "precision=0.54\n",
      "recall=0.54\n"
     ]
    }
   ],
   "source": [
    "def print_results(sample_size, precision, recall):\n",
    "    precision   = round(precision, 2)\n",
    "    recall      = round(recall, 2)\n",
    "    print(f'{sample_size=}')\n",
    "    print(f'{precision=}')\n",
    "    print(f'{recall=}')\n",
    "\n",
    "print_results(*model.test(NEW_TEST_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(tp):\n",
    "    if tp[0][0] == '__label__2':\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Negative'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
